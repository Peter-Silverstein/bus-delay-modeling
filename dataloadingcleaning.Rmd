---
title: "sea-gtfs-proj-data-cleaning"
author: "Peter Silverstein"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
# Loading Libraries

# General Use
library(tidyverse)
library(ggplot2)
library(here)
library(keyring)
library(furrr)

# PostgreSQL
library(DBI)
library(RPostgres)

# GIS and Mapping
library(sf)
library(lwgeom) 

# Census
library(tidycensus)
```

# Main Dataset

## Importing Data From SQL

```{r}
con <- dbConnect(RPostgres::Postgres(),
                 dbname = "sea-gtfs-data",
                 host = "localhost",
                 port = 5432,
                 user = "postgres",
                 password = "Parkour")

gtfs_realtime <- dbReadTable(con, "sea_gtfs_data")
gtfs_realtime <- tibble(gtfs_realtime)
```

## Cleaning Data/Verifying Types/Removing Duplicates

```{r}
# NEED TO FIGURE OUT TIMES OVER 24H!
gtfs_main <- gtfs_realtime %>%
  filter(projection == FALSE) %>%
  distinct(trip_id, stop_id, arrival_datetime, .keep_all = TRUE) %>%
  select(trip_id, route_id, stop_id, arrival_datetime, departure_datetime, pull_datetime) %>%
  mutate(trip_id = as.factor(trip_id),
         route_id = as.factor(route_id),
         stop_id = as.factor(stop_id)) %>%
  mutate(arrival_datetime = with_tz(arrival_datetime, "America/Los_Angeles"),
         departure_datetime = with_tz(departure_datetime, "America/Los_Angeles"),
         pull_datetime = with_tz(pull_datetime, "America/Los_Angeles"))

print(paste("Number of rows reduced from", nrow(gtfs_realtime), "to", nrow(gtfs_main)))
```

# Stop Times Dataset

## Importing Stop Times

```{r}
stop_times <- read_csv("Predictor Data Sets/gtfs-static-files/stop_times.txt") %>%
  select(trip_id, arrival_time, departure_time, stop_id, stop_sequence, shape_dist_traveled) %>%
  mutate(trip_id = as.factor(trip_id),
         stop_id = as.factor(stop_id)) %>%
  rename(sched_arrival_time = arrival_time,
         sched_departure_time = departure_time) %>%
  distinct(trip_id, stop_id, .keep_all = TRUE)
```

## Joining to Main Dataset

```{r}
gtfs_main_withstoptimes <- gtfs_main %>%
  left_join(stop_times, by = c("trip_id" = "trip_id",
                              "stop_id" = "stop_id"))
```

## Calculating Delay

```{r}
gtfs_main_withdelays <- gtfs_main_withstoptimes %>%
  mutate(actual_arrival_time = hms::as_hms(format(with_tz(arrival_datetime, "America/Los_Angeles"), "%H:%M:%S")),
         actual_departure_time = hms::as_hms(format(with_tz(departure_datetime, "America/Los_Angeles"), "%H:%M:%S")),
         date = as.POSIXct(format(with_tz(arrival_datetime, "America/Los_Angeles"), "%Y-%m-%d"))) %>%
  mutate(arrival_delay = as.numeric(actual_arrival_time - sched_arrival_time)) %>%
  select(date, 
         trip_id, 
         route_id, 
         stop_id, 
         sched_arrival_time, 
         sched_departure_time,
         actual_arrival_time,
         actual_departure_time,
         arrival_delay,
         stop_sequence,
         shape_dist_traveled,
         pull_datetime)
```

## Checking if Join worked, whether all rows have values for all fields

```{r}
test_df <- gtfs_main_withdelays %>%
  filter(is.na(date))

test_df

# Notes
  # 7626 rows have no date/arrival time
    # could this mean a skipped trip?
    # could not discern a pattern to the missing data, but I note that this pattern would appear in cases when stops        were skipped or routes were cancelled
  # 3915 rows have no route_id
    # could probably look up route_id based on trip_id
  # Stop ID 1746 has no stop_times join
    # I cannot discern why this is, exactly, but it's a very small portion of the sample
```

# Traffic by Time Bin

## Loading the dataset

```{r}
congestion_temporal <- read_csv("Predictor Data Sets/Traffic_Count_Studies_by_Hour_Bins-2.csv")
```

## Table w/ average traffic volume by day/hour

```{r}
congestion_dayhour <- congestion_temporal %>%
  mutate(datetime = as.POSIXct(ADD_DTTM, 
                               format = "%m/%d/%Y %I:%M:%S %p", 
                               tz = "America/Los_Angeles")) %>%
  filter(datetime > as.POSIXct("01-01-2015 00:00:00", 
                               format = "%m-%d-%Y %H:%M:%S",
                               tz = "America/Los_Angeles")) %>%
  group_by(WEEKDAY) %>%
  summarize(HR01 = mean(HR01_TOTAL),
            HR02 = mean(HR02_TOTAL),
            HR03 = mean(HR03_TOTAL),
            HR04 = mean(HR04_TOTAL),
            HR05 = mean(HR05_TOTAL),
            HR06 = mean(HR06_TOTAL),
            HR07 = mean(HR07_TOTAL),
            HR08 = mean(HR08_TOTAL),
            HR09 = mean(HR09_TOTAL),
            HR10 = mean(HR10_TOTAL),
            HR11 = mean(HR11_TOTAL),
            HR12 = mean(HR12_TOTAL),
            HR13 = mean(HR13_TOTAL),
            HR14 = mean(HR14_TOTAL),
            HR15 = mean(HR15_TOTAL),
            HR16 = mean(HR16_TOTAL),
            HR17 = mean(HR17_TOTAL),
            HR18 = mean(HR18_TOTAL),
            HR19 = mean(HR19_TOTAL),
            HR20 = mean(HR20_TOTAL),
            HR21 = mean(HR21_TOTAL),
            HR22 = mean(HR22_TOTAL),
            HR23 = mean(HR23_TOTAL),
            HR24 = mean(HR24_TOTAL)) %>%
  mutate(WEEKDAY_NAME = case_when(
    WEEKDAY == 1 ~ "Monday",
    WEEKDAY == 2 ~ "Tuesday",
    WEEKDAY == 3 ~ "Wednesday",
    WEEKDAY == 4 ~ "Thursday",
    WEEKDAY == 5 ~ "Friday",
    WEEKDAY == 6 ~ "Saturday",
    WEEKDAY == 7 ~ "Sunday")) %>%
  mutate(AVG_VOL = select(., HR01:HR24) %>% rowMeans(na.rm = TRUE)) %>%
  relocate(WEEKDAY_NAME, .after = WEEKDAY) %>%
  relocate(AVG_VOL, .after = WEEKDAY_NAME)

congestion_dh_longer <- congestion_dayhour %>%
  select(WEEKDAY_NAME, HR01:HR24) %>%
  pivot_longer(cols = -WEEKDAY_NAME,
               names_to = "HOUR",
               values_to = "avg_traffic_dayhour") %>%
  mutate(HOUR = as.numeric(gsub("[^0-9]","", HOUR)))
```

## Joining Day/Daypart Congestion

```{r}
# MAKE SURE TO REMOVE -1 VALUES
gtfs_main_withcongestion <- gtfs_main_withdelays %>%
  mutate(WEEKDAY = weekdays(date),
         HR = as.numeric(sched_arrival_time) %/% 3600) %>%
  left_join(select(.data = congestion_dayhour, WEEKDAY_NAME, AVG_VOL), 
            by = c("WEEKDAY" = "WEEKDAY_NAME")) %>%
  left_join(congestion_dh_longer,
            by = c("WEEKDAY" = "WEEKDAY_NAME",
                   "HR" = "HOUR")) %>%
    rename("weekday" = "WEEKDAY",
         "hr" = "HR",
         "avg_traffic_day" = "AVG_VOL")
```

# Creating Route-Stop Segments 

## Loading Relevant Data and Setting Geospatial Components
```{r}
# Loading trip data (directionality)
trips <- read.csv("Predictor Data Sets/gtfs-static-files/trips.txt") %>%
  select(trip_id, direction_id, shape_id, service_id)

# Loading spatial data (EPSG 4326!)
stops <- read.csv("Predictor Data Sets/gtfs-static-files/stops.txt") %>%
  st_as_sf(coords = c("stop_lon", "stop_lat"), crs = 4326) %>%
  select(stop_id, stop_name, wheelchair_boarding)

# Loading spatial data for routes
shapes <- read.csv("Predictor Data Sets/gtfs-static-files/shapes.txt") %>%
  arrange(shape_id, shape_pt_sequence) %>%
  st_as_sf(coords = c("shape_pt_lon", "shape_pt_lat"), crs = 4326) %>%
  group_by(shape_id) %>%
  summarise(do_union = FALSE) %>%
  st_cast("LINESTRING")

# Loading stop sequence for each trip
stop_times <- read.csv("Predictor Data Sets/gtfs-static-files/stop_times.txt") %>%
  select(trip_id, stop_id, stop_sequence, arrival_time)

```

## Function to Handle Directionality
```{r}
get_directional_route <- function(target_trip) {
  # Get shape_id and direction_id based on trip_id
  trip_info <- trips %>%
    filter(trip_id == target_trip) %>%
    select(shape_id, direction_id) %>%
    distinct()
  
  # Get the LINESTRING route shape based on shape_id
  base_route <- shapes %>%
    filter(shape_id == trip_info$shape_id)
  
  # If direction_id == 1, reverse the route shape
  if(trip_info$direction_id == 1) {
    reversed_route <- st_reverse(base_route)
    return(reversed_route)
  } else {
    return(base_route)
  }
}
```

## Associating Stops with Trips
```{r}
# Function that returns a spatial dataframe containing all stops for a trip
get_trip_stops <- function(target_trip) {
  stop_times %>%
    filter(trip_id == target_trip) %>%
    left_join(stops, by = "stop_id") %>%
    arrange(stop_sequence) %>%
    st_as_sf() %>%
    mutate(stop_order = row_number(),
           .before = geometry)
}
```

## Projection and Snapping
```{r}
# stops_sf is from get_trip_stops and route_sf is the directional route
snap_stops_to_route <- function(stops_sf, route_sf) {
  # Reprojection for more accurate distance calculation
  utm10n <- 32610
  route_proj <- st_transform(route_sf, utm10n)
  stops_proj <- st_transform(stops_sf, utm10n)
  
  # Find the point on line closest to stop
  snapped <- st_nearest_points(stops_proj, route_proj) %>%
    st_cast("POINT") %>%
    lapply(function(x) st_geometry(x)[[2]]) %>% # Return the snapped point, not the original
    st_as_sfc(crs = utm10n)
  
  # Convert back to original CRS
  st_transform(snapped, 4326)
}
```

## Position Calculation 
```{r}
calculate_line_positions <- function(snapped_points, route_line) {
  # Reprojection for more accurate distance calculation
  utm10n <- 32610
  snapped_proj <- st_transform(snapped_points, utm10n)
  route_proj <- st_transform(route_line, utm10n)
  
  # Makes sure that the route_line is a LINESTRING
  route_linestring <- st_geometry(route_proj)[[1]]
  
  # Returns the cumulative distance from the start for each stop
  positions <- st_line_locate_point(route_linestring, snapped_proj)
  
  # Return normalized 0-1 positions (i.e., fraction of route that a stop is along)
  normalized_positions <- positions / st_length(route_linestring)
  
  return(normalized_positions)
}
```

## Route Clipping
```{r}
clip_route_segment <- function(route, end_position) {
  # Reprojection for more accurate distance calculation
  utm10n <- 32610
  route_proj <- st_transform(route, utm10n)
  
  # Convert normalized distance to actual distance
  total_length <- st_length(route_proj)
  clip_distance <- total_length * end_position
  
  # Create substring up to target position
  clipped <- st_line_substring(
    st_geometry(route_proj)[[1]],
    from = 0,
    to = clip_distance
  )
    
  clipped_sf <- st_as_sf(clipped)
  st_transform(clipped_sf, st_crs(route))
}
```

# Traffic Flow Counts by Arterial
```{r}
plan(multisession) # Use all available cores

process_all_trips <- function(trip_ids) {
  future_map(trip_ids, ~{
    tryCatch({
      route <- get_directional_route(.x)
      stops <- get_trip_stops(.x)
      snapped <- snap_stops_to_route(stops, route)
      
      positions <- calculate_line_positions(snapped, route)
      
      # Generate all the clipped segments
      map2(positions, stops$stop_id, ~{
        clip_route_segment(route, .x) %>%
          mutate(
            trip_id = .x,
            stop_id = .y,
            clip_time = Sys.time()
          )
      }) %>%
        bind_rows()
      
    }, error = function(e){
      message("Error processing trip ", .x, ": ", e$message) 
      return(NULL)
    })
  }, .progress = TRUE) %>%
    bind_rows()
}
```

## Loading Data

```{r}
congestion_spatial_initial <- st_read(here("Predictor Data Sets",
                                   "2018_Traffic_Flow_Counts-shp",
                                   "2018_Traffic_Flow_Counts.shp"))
```

```{r}
# Select Columns; NOTE projected CRS is NAD83
congestion_spatial <- congestion_spatial_initial %>%
  select(STNAME_ORD, DOWNTOWN, AWDT, ADT, DATAQUALIT, FLAGS, SHAPE_Leng, geometry)
```

# Census Bureau 5-Year Estimates (2019-2023)
```{r}
# Using keyring package to keep my API key hidden
tidycensus_api_key <- key_get(service = "tidycensus_API", username = "my_tidycensus")
census_api_key(tidycensus_api_key)

ACSlist <- load_variables(2022, "acs5", cache = TRUE)
```

## Loading ACS Data from Tidycensus

```{r}
# Projection is NAD83(!!)
kingcounty_acs_blocks <- get_acs(state = "WA",
                                 county = "King",
                                 geography = "block group",
                                 variables = c(total_population = "B01003_001",
                                               median_income = "B19013_001",          # also have poverty level if needed
                                               race_basetotal = "B02001_001",
                                               race_white = "B02001_002",
                                               race_black = "B02001_003",
                                               race_nativeamerican = "B02001_004",
                                               race_asian = "B02001_005",
                                               race_nativehawaiianpi = "B02001_006",
                                               hisp_basetotal = "B03003_001",
                                               hisp_hispanic = "B03003_003",
                                               transp_basetotal = "B08134_001",
                                               tt_less10 = "B08134_002",
                                               tt_10to14 = "B08134_003",
                                               tt_15to19 = "B08134_004",
                                               tt_20to24 = "B08134_005",
                                               tt_25to29 = "B08134_006",
                                               tt_30to34 = "B08134_007",
                                               tt_35to44 = "B08134_008",
                                               tt_45to59 = "B08134_009",
                                               tt_60plus = "B08134_010",
                                               transp_mthd_carbusvan = "B08134_011",
                                               transp_mthd_public = "B08134_061",     # can break this down further by mthd
                                               transp_mthd_public_bus = "B08134_071", # can break this down further by tt
                                               agg_tt_overall = "B08136_001",
                                               agg_tt_public = "B08136_007",
                                               agg_tt_public_bus = "B08136_008",
                                               public_assistance_basetotal = "B19123_001",
                                               public_assistance_yes = "B19123_002",
                                               tenure_basetotal = "B25003_001",
                                               tenure_ownerocc = "B25003_002",
                                               tenure_renterocc = "B25003_003",
                                               units_instructure_basetotal = "B25024_001",
                                               units_instructure_1det = "B25024_002",
                                               units_instructure_1att = "B25024_003",
                                               units_instructure_2 = "B25024_004",
                                               units_instructure_3to4 = "B25024_005",
                                               units_instructure_5to9 = "B25024_006",
                                               units_instructure_10to19 = "B25024_007",
                                               units_instructure_20to49 = "B25024_008",
                                               units_instructure_50plus = "B25024_009",
                                               contractrent_agg = "B25060_001"),       # also have rent as % of income
                                 geometry = TRUE,
                                 keep_geo_vars = TRUE,
                                 year = 2023,
                                 output = "wide") %>%
  filter(ALAND != 0) %>% # Filter tracts that are 100% water
  mutate(GEOID = as.double(GEOID))
```

## Cleaning and transforming dataset (creating percentages)
```{r}
kcacs_blocks <- kingcounty_acs_blocks %>%
  mutate(ALAND_miles = ALAND/2589988) %>% # Converting sq meters to sq miles
  mutate(
        pop_per_sqmile = total_populationE / ALAND_miles,
        race_white_perc = race_whiteE / race_basetotalE,
        race_black_perc = race_blackE / race_basetotalE,
        race_asian_perc = race_asianE / race_basetotalE,
        race_nonwhite_perc = (race_basetotalE - race_whiteE) / race_basetotalE,
        hisp_perc = hisp_hispanicE / hisp_basetotalE,
        tt_less10_perc = tt_less10E / transp_basetotalE,
        tt_10to14_perc = tt_10to14E / transp_basetotalE,
        tt_15to19_perc = tt_15to19E / transp_basetotalE,
        tt_20to24_perc = tt_20to24E / transp_basetotalE,
        tt_25to29_perc = tt_25to29E / transp_basetotalE,
        tt_30to34_perc = tt_30to34E / transp_basetotalE,
        tt_35to44_perc = tt_35to44E / transp_basetotalE,
        tt_45to59_perc = tt_45to59E / transp_basetotalE,
        tt_60plus_perc = tt_60plusE / transp_basetotalE,
        transp_mthd_public_perc = transp_mthd_publicE / transp_basetotalE,
        transp_mthd_publicbus_perc = transp_mthd_public_busE / transp_basetotalE,
        public_assistance_yes_perc = public_assistance_yesE / public_assistance_basetotalE,
        tenure_ownerocc_perc = tenure_owneroccE / tenure_basetotalE,
        tenure_renterocc_perc = tenure_renteroccE / tenure_basetotalE,
        units_instructure_1_perc = 
          (units_instructure_1detE + units_instructure_1attE) / units_instructure_basetotalE,
        units_instructure_2_perc = units_instructure_2E / units_instructure_basetotalE,
        units_instructure_3to4_perc = units_instructure_3to4E / units_instructure_basetotalE,
        units_instructure_5to9_perc = units_instructure_5to9E / units_instructure_basetotalE,
        units_instructure_10to19_perc = units_instructure_10to19E / units_instructure_basetotalE,
        units_instructure_20to49_perc = units_instructure_20to49E/ units_instructure_basetotalE,
        units_instructure_50plus_perc = units_instructure_50plusE / units_instructure_basetotalE) %>%
  select(
        STATEFP,
        COUNTYFP,
        TRACTCE,
        BLKGRPCE,
        GEOIDFQ,
        GEOID,
        NAME.x,
        ALAND,
        AWATER,
        total_populationE,
        pop_per_sqmile,
        median_incomeE,
        race_white_perc,
        race_black_perc,
        race_asian_perc,
        race_nonwhite_perc,
        hisp_perc,
        tt_less10_perc,
        tt_10to14_perc,
        tt_15to19_perc,
        tt_20to24_perc,
        tt_25to29_perc,
        tt_30to34_perc,
        tt_35to44_perc,
        tt_45to59_perc,
        tt_60plus_perc,
        transp_mthd_public_perc,
        transp_mthd_publicbus_perc,
        agg_tt_overallE,
        agg_tt_publicE,
        agg_tt_public_busE,
        public_assistance_yes_perc,
        tenure_ownerocc_perc,
        tenure_renterocc_perc,
        units_instructure_1_perc,
        units_instructure_2_perc,
        units_instructure_3to4_perc,
        units_instructure_5to9_perc,
        units_instructure_10to19_perc,
        units_instructure_20to49_perc,
        units_instructure_50plus_perc,
        contractrent_aggE,
        geometry)
```

# Assorted Visualizations

## Traffic Volume by Day/Time

```{r}
# Ridgeline Plot of Traffic by Day
# Seems that I may want to log it
library(ggridges)

congestion_temporal_ridgeline <- congestion_temporal %>%
  mutate(WEEKDAY_NAME = as.factor(case_when(
    WEEKDAY == 1 ~ "Monday",
    WEEKDAY == 2 ~ "Tuesday",
    WEEKDAY == 3 ~ "Wednesday",
    WEEKDAY == 4 ~ "Thursday",
    WEEKDAY == 5 ~ "Friday",
    WEEKDAY == 6 ~ "Saturday",
    WEEKDAY == 7 ~ "Sunday"))) %>%
  filter(TOTAL != -1,
         TOTAL != 0)

ridgeline_trafficday <- ggplot(data = congestion_temporal_ridgeline,
                               aes(x = log(TOTAL),
                                   y = WEEKDAY_NAME)) + 
  geom_density_ridges(scale = 4) +
  scale_y_discrete(expand = c(0, 0)) + 
  scale_x_continuous(expand = c(0, 0)) + 
  coord_cartesian(clip = "off") + 
  theme_ridges()

ridgeline_trafficday
```

```{r}
# Plot of Average Congestion by Hour by Day
plot_congestion_hourday <- ggplot(data = congestion_dh_longer,
                                  aes(x = HOUR,
                                      y = avg_traffic_dayhour,
                                      color = WEEKDAY_NAME,
                                      linetype = WEEKDAY_NAME)) +
  geom_line()

plot_congestion_hourday
```

## Delay Plots

```{r}
# Delay by Day
library(ggridges)

delay_day_ridgeline <- gtfs_main_withcongestion %>%
  filter(arrival_delay > -2500)

ridgeline_delayday <- ggplot(data = delay_day_ridgeline,
                               aes(x = arrival_delay,
                                   y = weekday)) + 
  geom_density_ridges(scale = 4) +
  scale_y_discrete(expand = c(0, 0)) + 
  scale_x_continuous(expand = c(0, 0)) + 
  coord_cartesian(clip = "off") + 
  theme_ridges()

ridgeline_delayday
```

```{r}
# Scatterplot of avg congestion by avg delay
delay_traffic_data <- gtfs_main_withcongestion %>%
  filter(arrival_delay > -2500) %>%
  mutate(dayhour_traffic_bins = cut(avg_traffic_dayhour, 
                                    breaks = c(-Inf, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, Inf),
                                    labels = c("0-50", "50-100", "100-150", "150-200", "200-250", "250-300", "300-350",
                                               "350-400", "400-450", "450-500", "500-550", "550-600", "600+")))

scatter_delaytraffic <- ggplot(data = delay_traffic_data,
                               aes(x = dayhour_traffic_bins,
                                   y = arrival_delay,
                                   color = dayhour_traffic_bins)) +
  geom_jitter() + 
  theme(legend.position = "none")
scatter_delaytraffic
```

```{r}
# Scatterplot of avg congestion by avg delay
delay_traffic_data <- gtfs_main_withcongestion %>%
  filter(arrival_delay > -2500) %>%
  mutate(dayhour_traffic_bins = cut(avg_traffic_dayhour, 
                                    breaks = c(-Inf, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, Inf),
                                    labels = c("0-50", "50-100", "100-150", "150-200", "200-250", "250-300", "300-350",
                                               "350-400", "400-450", "450-500", "500-550", "550-600", "600+")))

scatter_delaytraffic <- ggplot(data = delay_traffic_data,
                               aes(x = arrival_delay,
                                   y = dayhour_traffic_bins,
                                   fill = dayhour_traffic_bins)) +
  geom_density_ridges() + 
  theme(legend.position = "none") +
  xlim(-500, 500)
scatter_delaytraffic
```

```{r}
# Delay by Day/Hour
day_hour_delay <- gtfs_main_withcongestion %>%
  filter(arrival_delay > 0,
         arrival_delay < 300) %>%
  select(hr, arrival_delay, weekday) %>%
  group_by(weekday, hr) %>%
  summarize(arrival_delay = mean(arrival_delay)) %>%
  ungroup()

plot_delay_hourday <- ggplot(data = day_hour_delay,
                                  aes(x = hr,
                                      y = arrival_delay,
                                      color = weekday,
                                      linetype = weekday)) +
  geom_line()

plot_delay_hourday
```

```{r}
# Delay for route_id = 100001 over time
route_100001_delay <- gtfs_main_withcongestion %>%
  filter(route_id == "100001") %>%
  select(arrival_delay, stop_sequence) %>%
  group_by(stop_sequence) %>%
  summarize(arrival_delay = mean(arrival_delay)) %>%
  ungroup()

plot_delay_100001 <- ggplot(data = route_100001_delay,
                                  aes(x = stop_sequence,
                                      y = arrival_delay)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE) + geom_line()

plot_delay_100001
```









































